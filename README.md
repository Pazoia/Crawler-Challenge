# Crawler Challenge

## Steps I took and how I approached the challenge

✅ ↦ Create a virtual env to keep dependencies and their versions isolated from local machine

```
python3 -m venv crawler
```

✅ ↦ Activate virtual env

```
source crawler/bin/activate
```

✅ ↦ Install dependencies in Pipfile  
I used the command below as I had already activate the `crawler` environment

```
pipenv sync
```

✅ ↦ Create a branch to hold the code with the changes on the parse method using css_selectors  
Extracting all acts starting with the letter `A`

```
git checkout parse-function-with-css-selectors
```

✅ ↦ Create a branch to hold the code with the changes on the parse method using css_selectors  
Extracting all acts starting with the letter `A` to `Z`

Merged this branch to main as it was the most advanced, having completed both challenges.
